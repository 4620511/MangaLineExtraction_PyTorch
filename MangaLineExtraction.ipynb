{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MangaLineExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rismr8AnFlqB"
      },
      "source": [
        "## MangaLineExtraction_Pytorch\n",
        "\n",
        "_This is an interactive demo of the paper [\"Deep Extraction of Manga Structural Lines\"](https://www.cse.cuhk.edu.hk/~ttwong/papers/linelearn/linelearn.html)_\n",
        "\n",
        "Firstly run the follwing cell to get the enviornment set up. Please ensure you have the GPU runtime setting set to \"on\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "UxDL2nO2-_Wq"
      },
      "source": [
        "#@title Environment setup\n",
        "\n",
        "%cd ~\n",
        "! git clone https://github.com/ljsabc/MangaLineExtraction_PyTorch.git\n",
        "%cd MangaLineExtraction_PyTorch\n",
        "! wget -O erika.pth https://github.com/ljsabc/MangaLineExtraction_PyTorch/releases/download/v1/erika.pth\n",
        "\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from model_torch import res_skip\n",
        "\n",
        "model = res_skip()\n",
        "model.load_state_dict(torch.load('erika.pth'))\n",
        "\n",
        "model.cuda();\n",
        "model.eval();\n",
        "\n",
        "print(\"Setup Complete\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZnrHmxFGN4k"
      },
      "source": [
        "### Test with your own image\n",
        "\n",
        "You may run this cell first. When the file upload button emerge in the output, select any picture from your local device and wait for the code to run. The output will be shown on the bottom. \n",
        "\n",
        "Right click on the result to save the output. Re-run this cell to upload and process again for a new round."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "xiMxM8ctCxIT"
      },
      "source": [
        "#@title File upload and processing\n",
        "\n",
        "uploaded = files.upload()\n",
        "outputLoc = None\n",
        "with torch.no_grad():\n",
        "    for imname in uploaded.keys():\n",
        "        srcc = cv2.imread(imname)\n",
        "        print(\"Original Image:\")\n",
        "        cv2_imshow(srcc)\n",
        "\n",
        "        src = cv2.imread(imname,cv2.IMREAD_GRAYSCALE)\n",
        "                \n",
        "        rows = int(np.ceil(src.shape[0]/16))*16\n",
        "        cols = int(np.ceil(src.shape[1]/16))*16\n",
        "        \n",
        "        # manually construct a batch. You can change it based on your usecases. \n",
        "        patch = np.ones((1,1,rows,cols),dtype=\"float32\")\n",
        "        patch[0,0,0:src.shape[0],0:src.shape[1]] = src\n",
        "\n",
        "        tensor = torch.from_numpy(patch).cuda()\n",
        "        y = model(tensor)\n",
        "        print(imname, torch.max(y), torch.min(y))\n",
        "\n",
        "        yc = y.cpu().numpy()[0,0,:,:]\n",
        "        yc[yc>255] = 255\n",
        "        yc[yc<0] = 0\n",
        "\n",
        "        head, tail = os.path.split(imname)\n",
        "        if not os.path.exists(\"output\"):\n",
        "            os.mkdir(\"output\")\n",
        "\n",
        "        print(\"Output Image:\")\n",
        "        output = yc[0:src.shape[0],0:src.shape[1]]\n",
        "        cv2_imshow(output)\n",
        "\n",
        "        outputLoc = \"output/\"+tail.replace(\".jpg\",\".png\")\n",
        "        cv2.imwrite(outputLoc,output)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}